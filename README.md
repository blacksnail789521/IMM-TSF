# IMM-TSF Benchmark Library

Welcome to the **IMM-TSF** benchmark library, part of the Time-IMM dataset collection for NeurIPS 2025 Datasets & Benchmarks Track. This repository provides tools for loading irregular, multimodal time-series data and running reproducible forecasting benchmarks.

---

## ðŸ“¦ Repository Structure

```
IMM-TSF/                     
â”œâ”€â”€ data/                   # Place your datasets here (raw and processed)
â”œâ”€â”€ fusions/                # Fusion model implementations
â”œâ”€â”€ layers/                 # Attention, correlation, and transformer layers
â”œâ”€â”€ lib/                    # Utility modules (parsing, evaluation, flows)
â”œâ”€â”€ models/                 # Base forecasting and generative models
â”œâ”€â”€ utils/                  # Helper utilities and scripts
â”œâ”€â”€ go.sh                   # Helper script to launch experiments
â”œâ”€â”€ main.py                 # Entry point for training and evaluation
â”œâ”€â”€ main_all.py             # Run all combinations of datasets and models
â”œâ”€â”€ main_all.sh             # Shell wrapper for batch experiments
â”œâ”€â”€ compute_text_embeddings.py  # Precompute LLM-based embeddings for text
â”œâ”€â”€ requirements.txt        # Python dependencies
â””â”€â”€ README.md               # This file
```

> **Note:** All your dataset files should reside under the `data/` folder.

---

## ðŸ“ Data Hierarchy

All datasets must follow the structure below for compatibility:

```
data/
â””â”€â”€ {dataset_name}/
    â””â”€â”€ processed/
        â””â”€â”€ {entity_id}/
            â”œâ”€â”€ time_series.csv         # Multivariate, irregular time-series data
            â”œâ”€â”€ text.csv                # Associated unstructured text data
            â””â”€â”€ text_embeddings_xxx.pt  # (Optional) Precomputed text embeddings
```

> âœ… **Example:** `data/EPA-Air/processed/Los_Angeles/time_series.csv` and `data/EPA-Air/processed/Los_Angeles/text.csv`

Each `{entity_id}` directory represents a unique data unit (e.g., a patient, sensor, or location) and should contain both structured and unstructured views of the data.

---

## ðŸ“¥ Download Dataset

Please download the datasets from one of the following sources:
* ðŸ’» **GitHub Repository:** [https://github.com/blacksnail789521/Time-IMM](https://github.com/blacksnail789521/Time-IMM)
* ðŸ“Ž **Kaggle Dataset:** [https://www.kaggle.com/datasets/blacksnail789521/time-imm](https://www.kaggle.com/datasets/blacksnail789521/time-imm)

After downloading, extract the files and place them under the appropriate folder within the `data/` directory, following the hierarchy above.

---

## ðŸ”§ Installation

1. Clone the repository:

   ```bash
   git clone https://github.com/your-org/IMM-TSF.git
   cd IMM-TSF
   ```

2. (Recommended) Create and activate a **conda** environment:

   ```bash
   conda create -n immtsf python=3.10
   conda activate immtsf
   ```

3. Install Python dependencies:

   ```bash
   pip install -r requirements.txt
   ```

> âœ… Using `conda` helps manage dependencies and avoid platform-specific conflicts.

---

## ðŸš€ Usage

You can run experiments in multiple ways:

### 1. Direct invocation (`main.py`)

Use command-line arguments for flexible training and evaluation:

```bash
python main.py \
  --data_name GDELT \
  --model_name tPatchGNN \
  --TTF_module TTF_RecAvg \
  --TTF_RecAvg MMF_GR_Add \
  --llm_model_fusion GPT2 \
  --batch_size 32 \
  --use_text_embeddings True \ 
  ...
```

Use `--help` to view all available flags.

### 2. `go.sh` wrapper

Edit default arguments in `main.py` and then launch an experiment:

```bash
. go.sh
```

This script sources predefined parameters and launches your run in one command.

---

## âš¡ Precomputing Text Embeddings

To speed up training by avoiding repeated LLM computation, you can precompute embeddings using:

```bash
python compute_text_embeddings.py
```

* This stores `text_embeddings_xxx.pt` under each `processed/{entity_id}/` folder.
* To use the precomputed embeddings, add `--use_text_embeddings True` when running `main.py`.
> **Note:** Please make sure you have at least **24GB total GPU RAM** to run **LLaMA 3.1** and **DeepSeek** models.

---

## ðŸ“Š Run All Benchmarks

To benchmark all modelâ€“dataset combinations:

```bash
. main_all.sh
```

This automates evaluation across all supported configurations.

---

## ðŸ”„ MIMIC Preprocessing

Due to access restrictions, raw MIMIC data must be downloaded manually. Please follow the instruction here:

```
data/MIMIC/mimic_preprocess.ipynb
```

This will generate processed files in:

```
data/MIMIC/processed/{entity_id}/
â”œâ”€â”€ time_series.csv
â””â”€â”€ text.csv
```